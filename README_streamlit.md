# Intelligent Bedrock Batch Inference UI

This Streamlit application provides a user-friendly interface for running and monitoring batch inference jobs using Amazon Bedrock through AWS Glue, as described in the main project README.

## Features

- **Start Batch Inference Jobs**: Easily configure and start batch inference jobs with a simple form interface
- **Job Tracking**: Monitor the status of all your batch inference jobs in real-time
- **Output Viewing**: View and access the output files generated by your jobs
- **Log Viewing**: Access job logs directly from the interface
- **Auto-refresh**: Automatically update job statuses without manual refreshing

## Setup Instructions

### Prerequisites

- Python 3.9 or higher (for local setup) OR Docker (for containerized setup)
- AWS CLI configured with appropriate permissions
- The AWS Glue job "intelligent-bedrock-batch-inference" deployed (see main README.md)

### Option 1: Local Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/intelligent-bedrock-batch-inference.git
   cd intelligent-bedrock-batch-inference
   ```

2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Run the Streamlit application:
   ```bash
   streamlit run app.py
   ```

4. Open your browser and navigate to the URL shown in the terminal (typically http://localhost:8501)

### Option 2: Docker Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/intelligent-bedrock-batch-inference.git
   cd intelligent-bedrock-batch-inference
   ```

2. Build and run using Docker Compose:
   ```bash
   docker-compose up -d
   ```

3. Open your browser and navigate to http://localhost:8501

4. To stop the application:
   ```bash
   docker-compose down
   ```

### Option 3: Docker Manual Setup

1. Build the Docker image:
   ```bash
   docker build -t bedrock-batch-inference-ui .
   ```

2. Run the Docker container:
   ```bash
   docker run -p 8501:8501 -v ~/.aws:/root/.aws:ro -e AWS_PROFILE=default -e AWS_REGION=us-west-2 bedrock-batch-inference-ui
   ```

3. Open your browser and navigate to http://localhost:8501

### AWS Configuration

You can configure your AWS credentials in two ways:

1. **Using AWS CLI**: Configure your AWS credentials using the AWS CLI:
   ```bash
   aws configure
   ```

2. **Using the Application**: Enter your AWS profile and region in the sidebar of the application.

## Usage

### Starting a Job

1. Navigate to the "Start Job" tab
2. Select the job type (InvokeModel or InvokeDifyWorkflow)
3. Fill in the required parameters:
   - Input S3 URI List: Comma-separated list of S3 URIs pointing to JSONL files
   - Output S3 URI: S3 URI where the output will be stored
   - RPM: Requests per minute limit
   - Max Workers: Maximum number of concurrent workers
   - Job-specific parameters (Model ID or Dify Workflow URL/Key)
4. Click "Start Job"

### Tracking Jobs

1. Navigate to the "Job Tracker" tab
2. View the list of all jobs and their statuses
3. Click on a job to expand its details
4. Use the "Refresh" button or enable "Auto-refresh" to update job statuses
5. View job logs and output files when available

## Job Types

### InvokeModel

This job type invokes Amazon Bedrock models directly:

- **Model ID**: The Bedrock model ID to use (e.g., anthropic.claude-3-haiku-20240307-v1:0)
- **AWS Access Key** (optional): Your AWS access key
- **AWS Secret Key** (optional): Your AWS secret key
- **AWS Region**: The AWS region where Bedrock is available

### InvokeDifyWorkflow

This job type invokes a Dify workflow:

- **Dify Workflow URL**: The URL of your Dify workflow
- **Dify Workflow Key**: The API key for your Dify workflow

## Troubleshooting

- **Job fails to start**: Ensure your AWS credentials have the necessary permissions
- **Cannot see job status**: Check if the job name matches "intelligent-bedrock-batch-inference"
- **Cannot see logs**: Ensure CloudWatch logs are enabled for your Glue job
- **Cannot see output files**: Check if the output S3 URI is correct and accessible

## License

See the main project LICENSE file for details.
